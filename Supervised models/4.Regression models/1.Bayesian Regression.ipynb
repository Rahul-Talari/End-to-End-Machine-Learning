{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Regression\n",
    "\n",
    "1. ARDRegression\n",
    "2. BayesianRidge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARDRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ARDRegression from sklearn.linear_model\n",
    "import sklearn.linear_model\n",
    "\n",
    "# Definition:\n",
    "\"\"\"\n",
    "ARDRegression:\n",
    "Automatic Relevance Determination (ARD) Regression is a probabilistic model for linear regression \n",
    "with automatic relevance determination for feature selection. It assumes a Gaussian likelihood \n",
    "and a Laplace prior for the weights. This model is useful for sparse regression problems where only a \n",
    "small subset of features are important.\n",
    "\n",
    "The hyperparameters control the modelâ€™s regularization and convergence criteria.\n",
    "\"\"\"\n",
    "\n",
    "# Code Example:\n",
    "ardregression_model = sklearn.linear_model.ARDRegression(\n",
    "    n_iter=300,                  # Maximum number of iterations (default=300)\n",
    "    tol=0.001,                   # Convergence tolerance (default=1e-3)\n",
    "    alpha_1=0.000001,            # Shape parameter for the Gamma distribution prior over alpha (default=1e-6)\n",
    "    alpha_2=0.000001,            # Inverse scale parameter for the Gamma distribution prior over alpha (default=1e-6)\n",
    "    lambda_1=0.000001,           # Shape parameter for the Gamma distribution prior over lambda (default=1e-6)\n",
    "    lambda_2=0.000001,           # Inverse scale parameter for the Gamma distribution prior over lambda (default=1e-6)\n",
    "    compute_score=False,         # Whether to compute the objective function at each step (default=False)\n",
    "    threshold_lambda=10000,      # Threshold for removing (pruning) weights with high precision (default=10000)\n",
    "    fit_intercept=True,          # Whether to fit an intercept (default=True)\n",
    "    copy_X=True,                 # Whether to copy X or not (default=True)\n",
    "    verbose=False                # Verbosity level (default=False)\n",
    ")\n",
    "\n",
    "# Hyperparameters:\n",
    "ardregression_hyperparameters = {\n",
    "    \"n_iter\": [100, 300, 500],               # Maximum number of iterations (default=300)\n",
    "    \"tol\": [1e-4, 1e-3, 0.001],              # Convergence tolerance (default=1e-3)\n",
    "    \"alpha_1\": [1e-6, 1e-5, 1e-4],           # Shape parameter for Gamma distribution prior over alpha (default=1e-6)\n",
    "    \"alpha_2\": [1e-6, 1e-5, 1e-4],           # Inverse scale parameter for Gamma distribution prior over alpha (default=1e-6)\n",
    "    \"lambda_1\": [1e-6, 1e-5, 1e-4],          # Shape parameter for Gamma distribution prior over lambda (default=1e-6)\n",
    "    \"lambda_2\": [1e-6, 1e-5, 1e-4],          # Inverse scale parameter for Gamma distribution prior over lambda (default=1e-6)\n",
    "    \"compute_score\": [True, False],          # Whether to compute the objective function (default=False)\n",
    "    \"threshold_lambda\": [1000, 10000, 100000],# Threshold for pruning weights with high precision (default=10000)\n",
    "    \"fit_intercept\": [True, False],          # Whether to fit an intercept (default=True)\n",
    "    \"copy_X\": [True, False],                 # Whether to copy X (default=True)\n",
    "    \"verbose\": [0, 1, 2]                     # Verbosity level (default=False)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "\n",
    "# Definition:\n",
    "\"\"\"\n",
    "BayesianRidge:\n",
    "Bayesian Ridge Regression is a probabilistic model for linear regression where the prior distribution \n",
    "on the coefficients is a Gaussian distribution with a mean of zero. It uses a conjugate prior and \n",
    "estimates the posterior distribution of the coefficients given the observed data. This model is \n",
    "regularized by adding a prior on the regression coefficients and noise variance.\n",
    "\n",
    "The hyperparameters control the prior distributions for the model coefficients and the precision \n",
    "of the noise.\n",
    "\"\"\"\n",
    "\n",
    "# Code Example:\n",
    "bayesianridge_model = sklearn.linear_model.BayesianRidge(\n",
    "    n_iter=300,                   # Maximum number of iterations (default=300)\n",
    "    tol=0.001,                    # Convergence tolerance (default=1e-3)\n",
    "    alpha_1=0.000001,             # Shape parameter for the Gamma distribution prior over alpha (default=1e-6)\n",
    "    alpha_2=0.000001,             # Inverse scale parameter for the Gamma distribution prior over alpha (default=1e-6)\n",
    "    lambda_1=0.000001,            # Shape parameter for the Gamma distribution prior over lambda (default=1e-6)\n",
    "    lambda_2=0.000001,            # Inverse scale parameter for the Gamma distribution prior over lambda (default=1e-6)\n",
    "    alpha_init=None,              # Initial value for alpha (precision of the noise). Default: 1/Var(y)\n",
    "    lambda_init=None,             # Initial value for lambda (precision of the weights). Default: 1\n",
    "    compute_score=False,          # If True, compute the log marginal likelihood at each iteration (default=False)\n",
    "    fit_intercept=True,           # Whether to calculate the intercept (default=True)\n",
    "    copy_X=True,                  # Whether to copy X (default=True)\n",
    "    verbose=False                 # Verbosity level (default=False)\n",
    ")\n",
    "\n",
    "# Hyperparameters:\n",
    "bayesianridge_hyperparameters = {\n",
    "    \"n_iter\": [100, 300, 500],           # Maximum number of iterations (default=300)\n",
    "    \"tol\": [1e-4, 1e-3, 0.001],          # Convergence tolerance (default=1e-3)\n",
    "    \"alpha_1\": [1e-6, 1e-5, 1e-4],       # Shape parameter for Gamma distribution prior over alpha (default=1e-6)\n",
    "    \"alpha_2\": [1e-6, 1e-5, 1e-4],       # Inverse scale parameter for Gamma distribution prior over alpha (default=1e-6)\n",
    "    \"lambda_1\": [1e-6, 1e-5, 1e-4],      # Shape parameter for Gamma distribution prior over lambda (default=1e-6)\n",
    "    \"lambda_2\": [1e-6, 1e-5, 1e-4],      # Inverse scale parameter for Gamma distribution prior over lambda (default=1e-6)\n",
    "    \"alpha_init\": [None, 0.1, 1],        # Initial value for alpha (precision of the noise)\n",
    "    \"lambda_init\": [None, 0.1, 1],       # Initial value for lambda (precision of the weights)\n",
    "    \"compute_score\": [True, False],      # Whether to compute the log marginal likelihood (default=False)\n",
    "    \"fit_intercept\": [True, False],      # Whether to fit an intercept (default=True)\n",
    "    \"copy_X\": [True, False],             # Whether to copy X (default=True)\n",
    "    \"verbose\": [0, 1, 2]                 # Verbosity level (default=False)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtaul_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
