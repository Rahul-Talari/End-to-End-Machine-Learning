{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-task Linear regressors with Variable selection:\n",
    "1. MultiTaskElasticNet\n",
    "2. MultiTaskElasticNetCV\n",
    "3. MultiTaskLasso\n",
    "4. MultiTaskLassoCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiTaskElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "\n",
    "MultiTaskElasticNet_model = sklearn.linear_model.MultiTaskElasticNet(\n",
    "    alpha=1,                        # Regularization strength. Default is 1.\n",
    "    l1_ratio=0.5,                   # The mix ratio between L1 (lasso) and L2 (ridge) regularization. Default is 0.5.\n",
    "    fit_intercept=True,             # Whether to calculate the intercept. If False, no intercept is used. Default is True.\n",
    "    copy_X=True,                    # Whether to copy the input data or modify it in place. Default is True.\n",
    "    max_iter=1000,                  # Maximum number of iterations. Default is 1000.\n",
    "    tol=0.0001,                     # Precision for convergence. Default is 0.0001.\n",
    "    warm_start=False,               # Whether to reuse the solution of the previous call to fit. Default is False.\n",
    "    random_state=None,              # Seed for reproducibility of results. Default is None.\n",
    "    selection=\"cyclic\"              # Method for coefficient update: \"cyclic\" or \"random\". Default is \"cyclic\".\n",
    ")\n",
    "\n",
    "MultiTaskElasticNet_hyperparameters = {\n",
    "    \"alpha\": [0.1, 0.5, 1.0, 5.0],\n",
    "    \"l1_ratio\": [0.1, 0.5, 0.7, 1.0],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"copy_X\": [True, False],\n",
    "    \"max_iter\": [1000, 5000, 10000],\n",
    "    \"tol\": [0.0001, 0.001, 0.01],\n",
    "    \"warm_start\": [True, False],\n",
    "    \"random_state\": [None, 42, 0],\n",
    "    \"selection\": [\"cyclic\", \"random\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "\n",
    "MultiTaskElasticNetCV_model = sklearn.linear_model.MultiTaskElasticNetCV(\n",
    "    l1_ratio=0.5,                    # The ratio between L1 (lasso) and L2 (ridge) regularization. Default is 0.5.\n",
    "    eps=0.001,                       # Length of the path. Default is 0.001. Determines the grid of alpha values.\n",
    "    n_alphas=100,                    # The number of alpha values to try. Default is 100.\n",
    "    alphas=None,                     # List of alpha values to use. If None, alpha values are set automatically.\n",
    "    fit_intercept=True,              # Whether to fit the intercept for the model. Default is True.\n",
    "    max_iter=1000,                   # Maximum number of iterations for optimization. Default is 1000.\n",
    "    tol=0.0001,                      # Tolerance for the optimization algorithm. Default is 0.0001.\n",
    "    cv=None,                         # Cross-validation splitting strategy. Default is None, which means no cross-validation.\n",
    "    copy_X=True,                     # Whether to copy the input data. Default is True.\n",
    "    verbose=0,                       # Verbosity level for the fitting process. Default is 0 (silent).\n",
    "    n_jobs=None,                     # Number of CPU cores to use for computation. Default is None (use one core).\n",
    "    random_state=None,               # Random seed for reproducibility of results. Default is None.\n",
    "    selection=\"cyclic\"               # The method for updating the coefficients. Options: \"cyclic\" or \"random\". Default is \"cyclic\".\n",
    ")\n",
    "MultiTaskElasticNetCV_hyperparameters = {\n",
    "    \"l1_ratio\": [0.1, 0.5, 0.7, 1.0],\n",
    "    \"eps\": [0.001, 0.01, 0.1],\n",
    "    \"n_alphas\": [50, 100, 200],\n",
    "    \"alphas\": [None, (0.1, 1.0, 10.0)],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"max_iter\": [1000, 5000, 10000],\n",
    "    \"tol\": [0.0001, 0.001, 0.01],\n",
    "    \"cv\": [3, 5, 10, None],\n",
    "    \"copy_X\": [True, False],\n",
    "    \"verbose\": [False, True],\n",
    "    \"n_jobs\": [1, -1],\n",
    "    \"random_state\": [None, 42, 0],\n",
    "    \"selection\": [\"cyclic\", \"random\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiTaskLasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "\n",
    "multitasklasso_model = sklearn.linear_model.MultiTaskLasso(\n",
    "    alpha=1.0,                       # Constant that multiplies the L1 term. Default is 1.0.\n",
    "    fit_intercept=True,               # Whether to calculate the intercept for this model. Default is True.\n",
    "    copy_X=True,                      # If True, X will be copied; else, it may be overwritten. Default is True.\n",
    "    max_iter=1000,                    # Maximum number of iterations. Default is 1000.\n",
    "    tol=0.0001,                       # Tolerance for optimization. Optimization continues until the dual gap is smaller than tol. Default is 1e-4.\n",
    "    warm_start=False,                 # Reuse the solution of the previous fit. Default is False.\n",
    "    random_state=None,                # The seed of the pseudo-random number generator. Default is None.\n",
    "    selection=\"cyclic\"                # Whether to update coefficients cyclically or randomly. Default is 'cyclic'.\n",
    ")\n",
    "\n",
    "# Hyperparameters for tuning\n",
    "multitasklasso_hyperparameters = {\n",
    "    \"alpha\": [0.1, 0.5, 1.0, 5.0],        \n",
    "    \"fit_intercept\": [True, False],       \n",
    "    \"copy_X\": [True, False],              \n",
    "    \"max_iter\": [1000, 5000, 10000],      \n",
    "    \"tol\": [0.0001, 0.001, 0.01],         \n",
    "    \"warm_start\": [True, False],          \n",
    "    \"random_state\": [None, 42, 0],        \n",
    "    \"selection\": [\"cyclic\", \"random\"],    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "\n",
    "multitasklassocv_model = sklearn.linear_model.MultiTaskLassoCV(\n",
    "    eps=0.001,                         # Length of the path. eps=1e-3 means that alpha_min / alpha_max = 1e-3.\n",
    "    n_alphas=100,                      # Number of alphas along the regularization path. Default is 100.\n",
    "    alphas=None,                       # List of alphas where to compute the models. If None, it is set automatically.\n",
    "    fit_intercept=True,                # Whether to calculate the intercept for this model. Default is True.\n",
    "    max_iter=1000,                     # Maximum number of iterations. Default is 1000.\n",
    "    tol=0.0001,                        # Tolerance for the optimization. Default is 1e-4.\n",
    "    copy_X=True,                       # If True, the input data X will be copied; otherwise, it may be overwritten. Default is True.\n",
    "    cv=None,                           # Cross-validation splitting strategy. Default is None (5-fold cross-validation).\n",
    "    verbose=False,                     # If True, the model fitting process will print out progress messages.\n",
    "    n_jobs=None,                       # Number of CPUs to use during the cross-validation. Default is None.\n",
    "    random_state=None,                 # The seed for the random number generator used in random coefficient updates. Default is None.\n",
    "    selection=\"cyclic\"                 # Method for updating coefficients: 'cyclic' or 'random'. Default is 'cyclic'.\n",
    ")\n",
    "\n",
    "# Hyperparameters for tuning\n",
    "multitasklassocv_hyperparameters = {\n",
    "    \"eps\": [0.001, 0.01, 0.1],\n",
    "    \"n_alphas\": [50, 100, 200],\n",
    "    \"alphas\": [None],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"max_iter\": [1000, 5000, 10000],\n",
    "    \"tol\": [0.0001, 0.001, 0.01],\n",
    "    \"copy_X\": [True, False],\n",
    "    \"cv\": [None, 5, 10],\n",
    "    \"verbose\": [True, False],\n",
    "    \"n_jobs\": [None, 1, -1],\n",
    "    \"random_state\": [None, 42, 0],\n",
    "    \"selection\": [\"cyclic\", \"random\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtaul_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
