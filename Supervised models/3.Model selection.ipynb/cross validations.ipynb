{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitter \n",
    "- Hyper-Parameter optimizers\n",
    "- Model Validation: cross validations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation Techniques Overview\n",
    "\n",
    "| **Category**                      | **Technique**                       | **Description**                                     |\n",
    "|------------------------------------|-------------------------------------|-----------------------------------------------------|\n",
    "| **Custom Splitters**               | `train_test_split`                  | Split arrays or matrices into random train and test subsets. |\n",
    "| **K-Fold Cross-Validation**        | `KFold`                             | K-Fold cross-validator.                            |\n",
    "|                                    | `RepeatedKFold`                     | Repeated K-Fold cross-validator.                   |\n",
    "|                                    | `StratifiedKFold`                   | Stratified K-Fold cross-validator.                 |\n",
    "|                                    | `RepeatedStratifiedKFold`           | Repeated Stratified K-Fold cross-validator.         |\n",
    "| **Leave-One-Out Cross-Validation** | `LeaveOneOut`                       | Leave-One-Out cross-validator.                     |\n",
    "|                                    | `LeavePOut`                         | Leave-P-Out cross-validator.                       |\n",
    "| **Group-based Cross-Validation**  | `GroupKFold`                        | K-fold iterator variant with non-overlapping groups. |\n",
    "|                                    | `StratifiedGroupKFold`              | Stratified K-Fold iterator variant with non-overlapping groups. |\n",
    "|                                    | `LeaveOneGroupOut`                  | Leave One Group Out cross-validator.               |\n",
    "|                                    | `LeavePGroupsOut`                   | Leave P Group(s) Out cross-validator.              |\n",
    "| **Shuffle-Based Cross-Validation** | `ShuffleSplit`                      | Random permutation cross-validator.                |\n",
    "|                                    |`StratifiedShuffleSplit` | Stratified ShuffleSplit cross-validator.           |\n",
    "|                                    | `GroupShuffleSplit`                 | Shuffle-Group(s)-Out cross-validation iterator.    |\n",
    "| **Time Series Cross-Validation**   | `TimeSeriesSplit`                   | Time Series cross-validator.                       |\n",
    "\n",
    "---\n",
    "\n",
    "*This table summarizes different cross-validation techniques, categorized by their method type, to help decide which one suits your model validation needs.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    'Input_data_df',\n",
    "    'target_data_df',\n",
    "    test_size=0.2,  # Fraction of the data to be used for testing (0.2 means 20% for testing)\n",
    "    train_size=None,  # Fraction of the data to be used for training (if None, it is set to complement of test_size)\n",
    "    random_state=None,  # Controls randomness for reproducibility. Use an integer to get the same split every time\n",
    "    shuffle=True,  # Whether to shuffle the data before splitting. Default is True (randomize order)\n",
    "    stratify=None  # If set to an array (like the target variable y), splits will be made in a stratified fashion\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "K-Fold Cross-Validation: The data is split into k equal folds. Each fold serves as a test set once, while\n",
    "                        the remaining k-1 folds are used for training. This process is repeated k times.   [Train size,Test size: k-1,1]\n",
    "'''\n",
    "import sklearn.model_selection\n",
    "\n",
    "# The first (n_samples % n_splits) folds have one extra sample, while the remaining folds have equal sizes\n",
    "kfold_cv = sklearn.model_selection.KFold(\n",
    "    n_splits=5,        # Number of splits (folds). Must be at least 2. Default is 5.\n",
    "    shuffle=False,     # Whether to shuffle the data before splitting. Default is False.\n",
    "    random_state=None  # Controls randomness when shuffle=True. Default is None (no reproducibility).\n",
    ")\n",
    "\n",
    "repeatedkfold_cv = sklearn.model_selection.RepeatedKFold(\n",
    "    n_splits=5,  # Number of splits (folds). Must be at least 2. Default is 5.\n",
    "    n_repeats=10,  # Number of times to repeat the cross-validation. Default is 10.\n",
    "    random_state=None  # Controls randomness of each repeated cross-validation instance. Default is None.\n",
    ")\n",
    "\n",
    "# Stratified ensures each fold has the same class distribution, useful for imbalanced classification problems.\n",
    "stratifiedkfold_cv = sklearn.model_selection.StratifiedKFold(\n",
    "    n_splits=5,         # Number of splits (folds). Must be at least 2. Default is 5.\n",
    "    shuffle=False,      # Whether to shuffle each class's samples before splitting into batches. Default is False.\n",
    "    random_state=None   # Controls the randomness of each fold when shuffle is True. Default is None.\n",
    ")\n",
    "\n",
    "repeatedstratifiedkfold_cv=sklearn.model_selection.RepeatedStratifiedKFold(\n",
    "    n_splits=5,  # Number of splits (folds). Must be at least 2. Default is 5.\n",
    "    n_repeats=10,  # Number of times to repeat the cross-validation. Default is 10.\n",
    "    random_state=None  # Controls randomness of each repeated cross-validation instance. Default is None.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LeavePOut CV: In each iteration, p samples are left out for testing, and the model is trained on the remaining n - p samples.\n",
    "              This process is repeated for all possible combinations of p samples being left out, resulting in multiple train/test splits.\n",
    "\"\"\"\n",
    "import sklearn.model_selection\n",
    "\n",
    "leaveoneout_technique=sklearn.model_selection.LeaveOneOut()     # LeaveOneOut() is equivalent to KFold(n_splits=n) and LeavePOut(p=1).\n",
    "leavepout_technique=sklearn.model_selection.LeavePOut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group-based CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GroupKFold is a cross-validation method that ensures all data from a group stays together in either the training or test set.\n",
    "It's useful when you have multiple records for the same entity, like measurements from the same person.\n",
    "This prevents data leakage and ensures realistic model validation\n",
    "'''\n",
    "\n",
    "import sklearn.model_selection\n",
    "\n",
    "groupkfold_cv=sklearn.model_selection.GroupKFold(n_splits='5')\n",
    "\n",
    "stratifiedgroupkfold_cv=sklearn.model_selection.StratifiedGroupKFold(\n",
    "     n_splits=5,         # Number of splits (folds). Must be at least 2. Default is 5.\n",
    "     shuffle=False,      # Whether to shuffle each class's samples before splitting into batches. Default is False.\n",
    "     random_state=None   # Controls the randomness of each fold when shuffle is True. Default is None.\n",
    ")\n",
    "\n",
    "leaveonegroupout_cv=sklearn.model_selection.LeaveOneGroupOut()\n",
    "\n",
    "leavepgroupsout_cv = sklearn.model_selection.LeavePGroupsOut(\n",
    "     n_groups=2,  # Number of groups (p) to leave out in the test split; For ex: if n_groups=2, two distinct groups will be left out for testing in each split.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "K-Fold Cross-Validation splits the data into k fixed folds and rotates the test set sequentially without shuffling between folds.\n",
    "\n",
    "ShuffleSplit randomly shuffles the data before each split, creating completely random and\n",
    "independent splits every time (not necessarily sequential).\n",
    "\"\"\"\n",
    "\n",
    "import sklearn.model_selection\n",
    "\n",
    "shuffle_split=sklearn.model_selection.ShuffleSplit(\n",
    "     n_splits=5,         # Number of splits (folds). Must be at least 2. Default is 5.\n",
    "     test_size=0.2,  # Fraction of the data to be used for testing (0.2 means 20% for testing)\n",
    "     train_size=None,  # Fraction of the data to be used for training (if None, it is set to complement of test_size)\n",
    "     random_state=None,  # Controls randomness for reproducibility. Use an integer to get the same split every time\n",
    ")\n",
    "stratifiedshufflesplit_cv=sklearn.model_selection.StratifiedShuffleSplit(\n",
    "     n_splits=5,         # Number of splits (folds). Must be at least 2. Default is 5.\n",
    "     test_size=0.2,  # Fraction of the data to be used for testing (0.2 means 20% for testing)\n",
    "     train_size=None,  # Fraction of the data to be used for training (if None, it is set to complement of test_size)\n",
    "     random_state=None,  # Controls randomness for reproducibility. Use an integer to get the same split every time\n",
    ")\n",
    "groupshufflesplit_cv=sklearn.model_selection.GroupShuffleSplit(\n",
    "     n_splits=5,         # Number of splits (folds). Must be at least 2. Default is 5.\n",
    "     test_size=0.2,  # Fraction of the data to be used for testing (0.2 means 20% for testing)\n",
    "     train_size=None,  # Fraction of the data to be used for training (if None, it is set to complement of test_size)\n",
    "     random_state=None,  # Controls randomness for reproducibility. Use an integer to get the same split every time\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter Optimizers\n",
    "<table>\n",
    "  <tr>\n",
    "    <th><font size=\"3\">Optimizer</font></th>\n",
    "    <th><font size=\"3\">Description</font></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font size=\"3\">GridSearchCV</font></td>\n",
    "    <td><font size=\"3\">Exhaustively searches all possible hyperparameter combinations, evaluating each one to find the best configuration.</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font size=\"3\">HalvingGridSearchCV</font></td>\n",
    "    <td><font size=\"3\">Efficiently tunes hyperparameters by starting with many combinations using fewer data points, and progressively allocating more to better-performing ones while discarding weaker ones.</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font size=\"3\">RandomizedSearchCV</font></td>\n",
    "    <td><font size=\"3\">Samples a fixed number of hyperparameter combinations randomly, often faster for large search spaces compared to GridSearchCV.</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font size=\"3\">HalvingRandomSearchCV</font></td>\n",
    "    <td><font size=\"3\">Efficiently tunes hyperparameters by randomly sampling and progressively allocating more resources to better-performing combinations while discarding weaker ones.</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font size=\"3\">ParameterGrid</font></td>\n",
    "    <td><font size=\"3\">ParameterGrid is a container for parameter values, while GridSearchCV tests all combinations of those values to find the best hyperparameters.</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font size=\"3\">ParameterSampler</font></td>\n",
    "    <td><font size=\"3\">ParameterSampler randomly samples parameter combinations from distributions, while RandomizedSearchCV evaluates these samples to find the best model.</font></td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# GridSearchCV Setup\n",
    "gridsearchcv_hpt = sklearn.model_selection.GridSearchCV(\n",
    "    estimator=None,  # The model to be tuned\n",
    "    param_grid=None,  # Hyperparameter grid\n",
    "    scoring='accuracy',  # Scoring method, can be a string like 'accuracy' or a custom scorer function\n",
    "    cv=5,  # Number of folds in cross-validation (or a custom cross-validator object)\n",
    "    verbose=1,  # Controls the verbosity of the output (higher numbers give more info)\n",
    "\n",
    "\n",
    "    n_jobs=-1,  # Number of CPU cores to use (-1 uses all available cores)\n",
    "    refit=True,  # Refits the best estimator on the whole dataset after searching\n",
    "    pre_dispatch=\"2*n_jobs\",  # Number of jobs to run in parallel before dispatching\n",
    "    error_score='raise',  # How errors are handled (default is 'raise' for throwing errors)\n",
    "    return_train_score=True  # Whether to include training scores in the results\n",
    ")\n",
    "\n",
    "gridsearchcv_hpt.best_score_\n",
    "gridsearchcv_hpt.best_params_\n",
    "gridsearchcv_hpt.best_estimator_\n",
    "gridsearchcv_hpt.best_index_\n",
    "gridsearchcv_hpt.cv_results_\n",
    "\n",
    "\n",
    "results = gridsearchcv_hpt.cv_results_               #Assuming gridsearchcv_hpt is already fitted  & get results from GridSearchCV\n",
    "\n",
    "df = pd.DataFrame(results)                           # Create a DataFrame to make the results more readable\n",
    "hyperparameters = pd.json_normalize(df['params'])    # 'params' column contains the dictionary of all pairs combination\n",
    "df = pd.concat([df, hyperparameters], axis=1)        # Concatenate the extracted hyperparameters with the DataFrame\n",
    "\n",
    "# Display the most important columns\n",
    "df_summary = df[['hpt_1', 'hpt_2', 'hpt_2','.....','mean_test_score', 'std_test_score', 'mean_fit_time', 'std_fit_time']]\n",
    "df_sorted = df_summary.sort_values(by=['mean_test_score', 'mean_fit_time'], ascending=[False, True])  # Sort by performance and training time\n",
    "df_sorted\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example_gridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Example data\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Define a simple SVC model\n",
    "model = SVC()\n",
    "\n",
    "# Define a small hyperparameter grid to search\n",
    "search_grid = {\n",
    "    'C': [0.1, 1, 10],               # Regularization parameter for SVC\n",
    "    'gamma': [0.01, 0.1, 1],         # Kernel coefficient for 'rbf' kernel\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "gridsearchcv_hpt = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=search_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    "    pre_dispatch=\"2*n_jobs\",\n",
    "    error_score='raise',\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "gridsearchcv_hpt.fit(X, y)\n",
    "\n",
    "# Retrieve results\n",
    "print(f\"Best Score: {gridsearchcv_hpt.best_score_}\")\n",
    "print(f\"Best Parameters: {gridsearchcv_hpt.best_params_}\")\n",
    "print(f\"Best Estimator: {gridsearchcv_hpt.best_estimator_}\")\n",
    "print(f\"Best Index: {gridsearchcv_hpt.best_index_}\")\n",
    "\n",
    "results = gridsearchcv_hpt.cv_results_               #Assuming gridsearchcv_hpt is already fitted  & get results from GridSearchCV\n",
    "\n",
    "df = pd.DataFrame(results)                           # Create a DataFrame to make the results more readable\n",
    "hyperparameters = pd.json_normalize(df['params'])    # 'params' column contains the dictionary of all pairs combination\n",
    "df = pd.concat([df, hyperparameters], axis=1)        # Concatenate the extracted hyperparameters with the DataFrame\n",
    "\n",
    "# Display the most important columns\n",
    "df_summary = df[['C', 'gamma', 'mean_test_score',  'mean_fit_time', 'std_test_score', 'std_fit_time']]\n",
    "df_sorted = df_summary.sort_values(by=['mean_test_score', 'mean_fit_time'], ascending=[False, True])  # Sort by performance and training time\n",
    "df_sorted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HalvingGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.svm import SVC\n",
    "from typing import Sequence, Mapping, Literal\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "\n",
    "halving_grid_search_cv = sklearn.model_selection.HalvingGridSearchCV(\n",
    "    estimator=None, \n",
    "    param_grid=None,\n",
    "    cv=5,                    # Cross-validation strategy. Default is 5-fold CV.\n",
    "    scoring=None,            # Metric to evaluate model performance, e.g., 'accuracy'. Default is the estimator's scoring method.\n",
    "    factor=3,                # The factor by which resources (e.g., samples) are increased at each iteration.\n",
    "    resource=\"n_samples\",    # Defines the resource to vary, default is \"n_samples\".\n",
    "\n",
    "    max_resources=\"auto\",  # Maximum resource to allocate. Default \"auto\" uses all available resources.\n",
    "    min_resources=\"exhaust\",  # Minimum resources for a configuration. \"exhaust\" uses the smallest possible value.\n",
    "    aggressive_elimination=False,  # If True, eliminates poor configurations more aggressively.\n",
    "    refit=True,                    # Whether to refit the best estimator on the entire dataset. Default is True.\n",
    "    error_score=np.nan,            # Value to assign when an error occurs during fitting. Default is NaN.\n",
    "    return_train_score=True,       # Whether to include training scores in the results. Default is True.\n",
    "    random_state=None,             # Seed for reproducibility. Default is None, meaning no fixed seed.\n",
    "    n_jobs=None,                   # Number of CPU cores to use for parallel processing. Default is None, using 1 core.\n",
    "    verbose=0                      # Controls the verbosity of output. Default is 0 (silent).\n",
    ")\n",
    "\n",
    "\n",
    "# Extract best parameters and results after fitting\n",
    "halving_grid_search_cv.best_score_\n",
    "halving_grid_search_cv.best_params_\n",
    "halving_grid_search_cv.best_estimator_\n",
    "halving_grid_search_cv.best_index_\n",
    "halving_grid_search_cv.cv_results_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv_results=halving_grid_search_cv.cv_results_\n",
    "results_df = pd.DataFrame(cv_results)\n",
    "\n",
    "hyperparameters_df = pd.json_normalize(results_df['params'])\n",
    "results_combined_df = pd.concat([results_df, hyperparameters_df], axis=1)\n",
    "\n",
    "# Display key columns: hyperparameters, mean test score, std test score, mean fit time, and std fit time\n",
    "df_summary = results_combined_df[['hpt_1', 'hpt_2', 'hpt_3', 'mean_test_score', 'std_test_score', 'mean_fit_time', 'std_fit_time']]\n",
    "df_sorted = df_summary.sort_values(by=['mean_test_score', 'mean_fit_time'], ascending=[False, True])\n",
    "df_sorted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of HalfGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load toy dataset (Iris dataset)\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Define a simple SVC model\n",
    "model = SVC()\n",
    "\n",
    "# Define a small hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],               # Regularization parameter for SVC\n",
    "    'gamma': [0.01, 0.1, 1],         # Kernel coefficient for 'rbf' kernel\n",
    "}\n",
    "\n",
    "# Set up HalvingGridSearchCV\n",
    "halving_grid_search_cv = sklearn.model_selection.HalvingGridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=param_grid,\n",
    "    factor=2,                        # Increase resources by a factor of 2\n",
    "    resource=\"n_samples\",            # Vary resources based on the number of samples\n",
    "    max_resources=\"auto\",            # Use all available resources\n",
    "    min_resources=\"exhaust\",         # Start with the smallest resources\n",
    "    cv=3,                            # 3-fold cross-validation\n",
    "    verbose=0,                       # Print progress\n",
    "    refit=True,                      # Refit the best model on the whole dataset\n",
    "    return_train_score=True          # Include training scores in results\n",
    ")\n",
    "\n",
    "# Fit the model with the data\n",
    "halving_grid_search_cv.fit(X, y)\n",
    "\n",
    "# Retrieve results\n",
    "print(f\"Best Score: {halving_grid_search_cv.best_score_}\")\n",
    "print(f\"Best Parameters: {halving_grid_search_cv.best_params_}\")\n",
    "print(f\"Best Estimator: {halving_grid_search_cv.best_estimator_}\")\n",
    "\n",
    "cv_results=halving_grid_search_cv.cv_results_\n",
    "results_df = pd.DataFrame(cv_results)\n",
    "\n",
    "hyperparameters_df = pd.json_normalize(results_df['params'])\n",
    "results_combined_df = pd.concat([results_df, hyperparameters_df], axis=1)\n",
    "\n",
    "# Display key columns: hyperparameters, mean test score, std test score, mean fit time, and std fit time\n",
    "df_summary = results_combined_df[['C', 'gamma', 'mean_test_score', 'std_test_score', 'mean_fit_time', 'std_fit_time']]\n",
    "df_sorted = df_summary.sort_values(by=['mean_test_score', 'mean_fit_time'], ascending=[False, True])\n",
    "df_sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "from sklearn.base import BaseEstimator\n",
    "from typing import Sequence, Mapping\n",
    "import numpy as np\n",
    "\n",
    "randomizedsearchcv_hpt = sklearn.model_selection.RandomizedSearchCV(\n",
    "    estimator=None,             # The model to be tuned. Default is None, must be set to a specific estimator like RandomForestClassifier.\n",
    "    param_distributions=None,   # The distribution of hyperparameters to sample from. Default is None, meaning no search is done.\n",
    "    n_iter=10,                  # The number of iterations (samples) for random search. Default is 10.\n",
    "    scoring=None,               # A string (e.g., 'accuracy') or callable scoring function. Default is None, which means using the estimator's default scoring method.\n",
    "    n_jobs=None,                # Number of CPU cores to use for parallel processing. Default is None, which means using a single core.\n",
    "    refit=True,                 # Whether to refit the best model on the entire dataset after search. Default is True.\n",
    "    cv=None,                    # Cross-validation splitting strategy. Default is None, which uses 5-fold cross-validation.\n",
    "    verbose=0,                  # Controls the verbosity of the output. Default is 0, which means no output.\n",
    "    pre_dispatch=\"2*n_jobs\",    # Number of jobs to run in parallel before dispatching. Default is \"2*n_jobs\", which means two times the number of jobs.\n",
    "    random_state=None,          # The seed for random number generation to ensure reproducibility. Default is None (no fixed seed).\n",
    "    error_score=np.nan,         # The value to assign when an error occurs during fitting. Default is NaN.\n",
    "    return_train_score=False    # Whether to include training scores in the results. Default is False.\n",
    ")\n",
    "\n",
    "randomizedsearchcv_hpt.best_score_\n",
    "randomizedsearchcv_hpt.best_params_\n",
    "randomizedsearchcv_hpt.best_estimator_\n",
    "randomizedsearchcv_hpt.best_index_\n",
    "randomizedsearchcv_hpt.cv_results_\n",
    "\n",
    "\n",
    "results = randomizedsearchcv_hpt.cv_results_               #Assuming gridsearchcv_hpt is already fitted  & get results from GridSearchCV\n",
    "\n",
    "df = pd.DataFrame(results)                           # Create a DataFrame to make the results more readable\n",
    "hyperparameters = pd.json_normalize(df['params'])    # 'params' column contains the dictionary of all pairs combination\n",
    "df = pd.concat([df, hyperparameters], axis=1)        # Concatenate the extracted hyperparameters with the DataFrame\n",
    "\n",
    "# Display the most important columns\n",
    "df_summary = df[['hpt_1', 'hpt_2', 'hpt_2','.....','mean_test_score', 'std_test_score', 'mean_fit_time', 'std_fit_time']]\n",
    "df_sorted = df_summary.sort_values(by=['mean_test_score', 'mean_fit_time'], ascending=[False, True])  # Sort by performance and training time\n",
    "df_sorted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of randomizedsearchcv_hpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "\n",
    "# Example data\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Define SVC model\n",
    "model = SVC()\n",
    "\n",
    "# Define parameter distributions for SVC\n",
    "param_distributions = {\n",
    "    'C': [0.1, 1, 10],          # Regularization parameter for SVC\n",
    "    'gamma': [0.01, 0.1, 1],    # Kernel coefficient for 'rbf' kernel\n",
    "    'kernel': ['linear', 'rbf'],# Kernel type: linear or radial basis function (rbf)\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "randomizedsearchcv_hpt = sklearn.model_selection.RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_distributions,  # Using param_distributions here\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    "    pre_dispatch=\"2*n_jobs\",\n",
    "    error_score='raise',\n",
    "    return_train_score=True,\n",
    "    n_iter=10  # Number of iterations for random sampling\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "randomizedsearchcv_hpt.fit(X, y)\n",
    "\n",
    "# Retrieve results\n",
    "print(f\"Best Score: {randomizedsearchcv_hpt.best_score_}\")\n",
    "print(f\"Best Parameters: {randomizedsearchcv_hpt.best_params_}\")\n",
    "print(f\"Best Estimator: {randomizedsearchcv_hpt.best_estimator_}\")\n",
    "print(f\"Best Index: {randomizedsearchcv_hpt.best_index_}\")\n",
    "\n",
    "# Retrieve and format the results\n",
    "results = randomizedsearchcv_hpt.cv_results_  # Get results from RandomizedSearchCV\n",
    "\n",
    "# Create a DataFrame for readability\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Normalize the 'params' column to separate hyperparameters\n",
    "hyperparameters = pd.json_normalize(df['params'])\n",
    "\n",
    "# Concatenate the hyperparameters with the results DataFrame\n",
    "df = pd.concat([df, hyperparameters], axis=1)\n",
    "\n",
    "# Display important columns and sort by performance\n",
    "df_summary = df[['C', 'gamma', 'kernel', 'mean_test_score', 'mean_fit_time', 'std_test_score', 'std_fit_time']]\n",
    "df_sorted = df_summary.sort_values(by=['mean_test_score', 'mean_fit_time'], ascending=[False, True])\n",
    "\n",
    "# Display sorted results\n",
    "df_sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HalvingRandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "\n",
    "Halving_randomsearchCV_hpt=sklearn.model_selection.HalvingRandomSearchCV(\n",
    "    estimator=None, \n",
    "    param_grid=None,\n",
    "    cv=5,                    # Cross-validation strategy. Default is 5-fold CV.\n",
    "    scoring=None,            # Metric to evaluate model performance, e.g., 'accuracy'. Default is the estimator's scoring method.\n",
    "    factor=3,                # The factor by which resources (e.g., samples) are increased at each iteration.\n",
    "    resource=\"n_samples\",    # Defines the resource to vary, default is \"n_samples\".\n",
    "\n",
    "    max_resources=\"auto\",          # Maximum resource to allocate. Default \"auto\" uses all available resources.\n",
    "    min_resources=\"exhaust\",       # Minimum resources for a configuration. \"exhaust\" uses the smallest possible value.\n",
    "    aggressive_elimination=False,  # If True, eliminates poor configurations more aggressively.\n",
    "    refit=True,                    # Whether to refit the best estimator on the entire dataset. Default is True.\n",
    "    error_score=np.nan,            # Value to assign when an error occurs during fitting. Default is NaN.\n",
    "    return_train_score=True,       # Whether to include training scores in the results. Default is True.\n",
    "    random_state=None,             # Seed for reproducibility. Default is None, meaning no fixed seed.\n",
    "    n_jobs=None,                   # Number of CPU cores to use for parallel processing. Default is None, using 1 core.\n",
    "    verbose=0                      # Controls the verbosity of output. Default is 0 (silent).\n",
    ")\n",
    "\n",
    "\n",
    "# Extract best parameters and results after fitting\n",
    "Halving_randomsearchCV_hpt.best_score_\n",
    "Halving_randomsearchCV_hpt.best_params_\n",
    "Halving_randomsearchCV_hpt.best_estimator_\n",
    "Halving_randomsearchCV_hpt.best_index_\n",
    "Halving_randomsearchCV_hpt.cv_results_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv_results=Halving_randomsearchCV_hpt.cv_results_\n",
    "results_df = pd.DataFrame(cv_results)\n",
    "\n",
    "hyperparameters_df = pd.json_normalize(results_df['params'])\n",
    "results_combined_df = pd.concat([results_df, hyperparameters_df], axis=1)\n",
    "\n",
    "# Display key columns: hyperparameters, mean test score, std test score, mean fit time, and std fit time\n",
    "df_summary = results_combined_df[['hpt_1', 'hpt_2', 'hpt_3', 'mean_test_score', 'std_test_score', 'mean_fit_time', 'std_fit_time']]\n",
    "df_sorted = df_summary.sort_values(by=['mean_test_score', 'mean_fit_time'], ascending=[False, True])\n",
    "df_sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of HalvingRandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Define the SVC model\n",
    "model = SVC()\n",
    "\n",
    "# Define a small hyperparameter grid to search\n",
    "param_distributions = {\n",
    "    'C': [0.1, 1, 10],                # Regularization parameter for SVC\n",
    "    'gamma': [0.01, 0.1, 1],          # Kernel coefficient for 'rbf' kernel\n",
    "}\n",
    "\n",
    "# Set up HalvingRandomSearchCV\n",
    "halving_randomsearch_cv = sklearn.model_selection.HalvingRandomSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_distributions,\n",
    "    factor=2,                         # Increase resources by a factor of 2\n",
    "    resource=\"n_samples\",             # Vary resources based on the number of samples\n",
    "    max_resources=\"auto\",             # Use all available resources\n",
    "    min_resources=\"smallest\",          # Start with the smallest resources\n",
    "    cv=3,                             # 3-fold cross-validation\n",
    "    verbose=0,                        # Print progress\n",
    "    refit=True,                       # Refit the best model on the whole dataset\n",
    "    return_train_score=True           # Include training scores in results\n",
    ")\n",
    "\n",
    "# Fit the model with the data\n",
    "halving_randomsearch_cv.fit(X, y)\n",
    "\n",
    "# Retrieve results\n",
    "print(f\"Best Score: {halving_randomsearch_cv.best_score_}\")\n",
    "print(f\"Best Parameters: {halving_randomsearch_cv.best_params_}\")\n",
    "print(f\"Best Estimator: {halving_randomsearch_cv.best_estimator_}\")\n",
    "\n",
    "# Display the results in a DataFrame\n",
    "cv_results = halving_randomsearch_cv.cv_results_\n",
    "results_df = pd.DataFrame(cv_results)\n",
    "\n",
    "# Extract hyperparameters from the 'params' column\n",
    "hyperparameters_df = pd.json_normalize(results_df['params'])\n",
    "\n",
    "# Combine the results with hyperparameters\n",
    "results_combined_df = pd.concat([results_df, hyperparameters_df], axis=1)\n",
    "\n",
    "# Display the most important columns: hyperparameters, mean test score, std test score, mean fit time, and std fit time\n",
    "df_summary = results_combined_df[['C', 'gamma', 'mean_test_score', 'std_test_score', 'mean_fit_time', 'std_fit_time']]\n",
    "df_sorted = df_summary.sort_values(by=['mean_test_score', 'mean_fit_time'], ascending=[False, True])\n",
    "\n",
    "# Display the sorted results\n",
    "print(df_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Concept**            | **Description**                                                                                                               |\n",
    "|------------------------|-------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Learning Curve**      | Shows how performance changes with increasing training data, helping identify overfitting or underfitting.                   |\n",
    "| **Visualization Tool**  | `LearningCurveDisplay`                                                                                                        |\n",
    "| **Validation Curve**    | Shows how performance changes with different hyperparameter values, helping find the optimal setting.                         |\n",
    "| **Permutation Test Score** | Helps check if your model's performance is better than random chance. It shuffles the labels in the data, retrains the model, and compares the results with the original performance. A significantly higher accuracy than random scores means the performance is likely meaningful. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "\n",
    "train_size_abs, train_scores, test_scores = sklearn.model_selection.learning_curve(\n",
    "    tree,                                # Estimator (model) to use for fitting the data\n",
    "    X,                                   # Input dataframe\n",
    "    y,                                   # Target dataframe\n",
    "    train_sizes=[0.3, 0.6, 0.9],         # Training set sizes to evaluate (30%, 60%, and 90% of the data)\n",
    "    cv=None,                             # Cross-validation splitting strategy (None means no cross-validation, uses 5-fold by default)\n",
    "    scoring=None,                        # Evaluation metric (None means the model's default score will be used, e.g., accuracy for classification)\n",
    "    exploit_incremental_learning=False,  # If True, will use partial fitting if the model supports it (useful for large datasets)\n",
    "    n_jobs=None,                         # Number of CPU cores to use for parallel computation (None means 1, -1 means all available cores)\n",
    "    pre_dispatch=\"all\",                  # Number of jobs to pre-dispatch for parallel execution (controls parallelism)\n",
    "    verbose=0,                           # Verbosity level, 0 means no output, higher numbers give more details about the process\n",
    "    shuffle=False,                       # If True, the data will be shuffled before splitting into cross-validation folds\n",
    "    random_state=None,                   # Random state for reproducibility of the results (if None, itâ€™s randomly initialized)\n",
    "    error_score=np.nan,                  # Value to assign when an error occurs during fitting (e.g., np.nan, or 'raise' to raise an error)\n",
    "    return_times=False,                  # If True, will also return the time taken for each fitting operation\n",
    "    fit_params=None                      # Additional parameters to pass to the fit method of the estimator\n",
    ")\n",
    "\n",
    "display = sklearn.model_selection.LearningCurveDisplay(\n",
    "    train_sizes=train_size_abs,  # The absolute sizes of the training set for each evaluation\n",
    "    train_scores=train_scores,  # The training scores (e.g., accuracy) for each training set size\n",
    "    test_scores=test_scores,  # The test scores (e.g., accuracy) for each training set size\n",
    "    score_name=\"Score\",  # The name of the metric being plotted (e.g., \"Accuracy\", \"Score\")\n",
    ")\n",
    "\n",
    "# Plot the learning curve\n",
    "display.plot()  # This generates the plot of training and test scores across the training set sizes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example  for learning curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import LearningCurveDisplay, learning_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Initialize the DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=100)\n",
    "\n",
    "# Generate the learning curve data\n",
    "train_sizes, train_scores, test_scores = learning_curve(tree, X, y)\n",
    "\n",
    "# Create the LearningCurveDisplay object\n",
    "display = LearningCurveDisplay(\n",
    "    train_sizes=train_sizes,\n",
    "    train_scores=train_scores,\n",
    "    test_scores=test_scores,\n",
    "    score_name=\"Accuracy\"  # Better to specify the score type\n",
    ")\n",
    "\n",
    "# Plot with gridlines and labels for clarity\n",
    "display.plot()\n",
    "plt.grid(True)  # Add gridlines to make it easier to see the values\n",
    "plt.title(\"Learning Curve (Accuracy vs Training Set Size)\")  # Add a title\n",
    "plt.xlabel(\"Training Set Size\")  # Label for the x-axis\n",
    "plt.ylabel(\"Accuracy Score\")  # Label for the y-axis\n",
    "plt.show()  # Show the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A validation curve evaluates a model's performance by testing different values of a hyperparameter, such as C,\n",
    "to see how it affects training and test accuracy.\n",
    "It helps identify the best hyperparameter value by showing whether the model is overfitting, underfitting, or generalizing well.\n",
    "'''\n",
    "train_scores, test_scores = sklearn.model_selection.validation_curve(\n",
    "    estimator=SVC(),  # The model to evaluate (Support Vector Classifier)\n",
    "    X=X_train,  # The training feature set\n",
    "    y=y_train,  # The target labels for training data\n",
    "    param_name='C',  # The hyperparameter name ('C')\n",
    "    param_range=[0.1, 1, 10, 100],  # The range of values for 'C' to test\n",
    "    cv=5,  # The number of cross-validation folds (5-fold cross-validation)\n",
    "    scoring='accuracy',  # The scoring metric to evaluate (accuracy)\n",
    "    n_jobs=-1,  # Use all available CPU cores for parallel processing\n",
    "    verbose=1,  # Display progress information\n",
    "    error_score='raise'  # Raise an error if fitting fails (or can be a numeric value)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example for validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average train accuracy is 0.81\n",
      "The average test accuracy is 0.81\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification  # Importing to generate a synthetic classification dataset\n",
    "from sklearn.model_selection import validation_curve  # Importing the validation_curve function to evaluate hyperparameters\n",
    "from sklearn.linear_model import LogisticRegression  # Importing Logistic Regression classifier\n",
    "import numpy as np  # For creating a range of values for hyperparameters\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "\n",
    "# Generate a synthetic classification dataset with 1,000 samples and default random state\n",
    "X, y = make_classification(n_samples=1_000, random_state=0)\n",
    "\n",
    "# Initialize the LogisticRegression model\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# Define the hyperparameter 'C' and a range of values (logarithmic scale from 1e-8 to 1e3)\n",
    "param_name, param_range = \"C\", np.logspace(-8, 3, 10)\n",
    "\n",
    "# Run validation curve to evaluate model performance across different values of 'C'\n",
    "train_scores, test_scores = validation_curve(\n",
    "    logistic_regression,  # The classifier to evaluate\n",
    "    X,  # The input features\n",
    "    y,  # The target labels\n",
    "    param_name=param_name,  # The hyperparameter to tune ('C')\n",
    "    param_range=param_range  # The range of values for 'C' to evaluate\n",
    ")\n",
    "\n",
    "# Print the average accuracy on the training set across all values of 'C'\n",
    "print(f\"The average train accuracy is {train_scores.mean():.2f}\")\n",
    "\n",
    "# Print the average accuracy on the test set across all values of 'C'\n",
    "print(f\"The average test accuracy is {test_scores.mean():.2f}\")\n",
    "\n",
    "# Plotting the training and test scores across different values of 'C'\n",
    "plt.plot(param_range, train_scores.mean(axis=1), label=\"Train Scores\")\n",
    "plt.plot(param_range, test_scores.mean(axis=1), label=\"Test Scores\")\n",
    "plt.xscale('log')  # Set x-axis to logarithmic scale\n",
    "plt.xlabel('Hyperparameter C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Curve for Logistic Regression')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation_test_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import permutation_test_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Example usage of permutation_test_score\n",
    "permutation_test_score = sklearn.model_selection.permutation_test_score(\n",
    "    estimator=SVC(),     # The estimator to evaluate (Support Vector Classifier in this case)\n",
    "    X=X,                 # Input dataframe\n",
    "    y=y,                 # Target dataframe\n",
    "    groups=None,         # Group labels for group cross-validation (default is None)\n",
    "    cv=5,                # Cross-validation splitting strategy (default is 5-fold cross-validation)\n",
    "    n_permutations=100,  # Number of times to permute the data (default is 100)\n",
    "    n_jobs=None,         # Number of jobs to run in parallel (default is None, i.e., no parallelization)\n",
    "    random_state=0,      # Random seed for reproducibility (default is 0)\n",
    "    verbose=0,           # Verbosity level (default is 0, no output)\n",
    "    scoring=None,        # Scoring metric (default is None, uses estimator's default scoring)\n",
    "    fit_params=None      # Parameters passed to the fit method (default is None)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation_test_score example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Score: 0.810\n",
      "Permutation Scores: 0.505 +/- 0.057\n",
      "P-value: 0.010\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification  # Importing dataset for classification\n",
    "from sklearn.linear_model import LogisticRegression  # Importing Logistic Regression classifier\n",
    "from sklearn.model_selection import permutation_test_score  # Importing permutation test function\n",
    "\n",
    "# Generate a synthetic classification dataset\n",
    "X, y = make_classification(random_state=0)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "# Perform the permutation test to evaluate the model's significance\n",
    "score, permutation_scores, pvalue = permutation_test_score(\n",
    "    estimator, X, y, random_state=0\n",
    ")\n",
    "\n",
    "# Print the original score, mean and standard deviation of permutation scores, and p-value\n",
    "print(f\"Original Score: {score:.3f}\")\n",
    "print(f\"Permutation Scores: {permutation_scores.mean():.3f} +/- {permutation_scores.std():.3f}\")\n",
    "print(f\"P-value: {pvalue:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtaul_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
