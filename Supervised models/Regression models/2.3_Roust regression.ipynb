{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Robust Regressors:\n",
    "\n",
    "1. HuberRegressor\n",
    "2. QuantileRegressor\n",
    "3. RANSACRegressor\n",
    "4. TheilSenRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuberRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition:\n",
    "\"\"\"\n",
    "HuberRegressor:\n",
    "A robust linear regression model from sklearn.linear_model that uses the Huber loss function.\n",
    "It combines squared loss for inliers and absolute loss for outliers, making it robust to \n",
    "outliers in the dataset.\n",
    "\"\"\"\n",
    "\n",
    "# Code Example:\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "# Initialize HuberRegressor with default or custom parameters\n",
    "huber_regressor = HuberRegressor(\n",
    "    epsilon=1.35,       # Controls outlier classification; smaller values are more robust\n",
    "    max_iter=100,       # Maximum number of iterations for optimization\n",
    "    alpha=0.0001,       # L2 regularization strength\n",
    "    warm_start=False,   # Whether to reuse previous fit's coefficients\n",
    "    fit_intercept=True, # Whether to calculate the intercept for this model\n",
    "    tol=1e-5            # Tolerance for stopping criteria\n",
    ")\n",
    "\n",
    "huber_regressor_hyperparameters = {\n",
    "    \"epsilon\": [1.0, 1.35, 1.5, 2.0],          # Controls outlier classification robustness\n",
    "    \"alpha\": [0.0001, 0.001, 0.01, 0.1],       # Strength of L2 regularization\n",
    "    \"fit_intercept\": [True, False],            # Whether to fit the intercept term\n",
    "    \"max_iter\": [100, 500, 1000, 5000],        # Maximum number of iterations\n",
    "    \"tol\": [1e-5, 1e-4, 1e-3, 1e-2],           # Convergence tolerance for optimization\n",
    "    \"warm_start\": [True, False],               # Whether to reuse previous fit's solution\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition:\n",
    "\"\"\"\n",
    "QuantileRegressor:\n",
    "A linear regression model from sklearn.linear_model that optimizes the pinball loss for a specified quantile, \n",
    "making it robust to outliers. This model uses L1 regularization similar to Lasso regression.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "\n",
    "quantile_regressor = QuantileRegressor(\n",
    "    quantile=0.5,            # Predicts the specified quantile (default is 0.5, i.e., median)\n",
    "    alpha=1.0,               # L1 regularization strength\n",
    "    fit_intercept=True,      # Whether to calculate the intercept for this model\n",
    "    solver=\"highs\",          # Optimization method for linear programming\n",
    "    solver_options=None      # Additional solver-specific options\n",
    ")\n",
    "\n",
    "quantile_regressor_hyperparameters = {\n",
    "    \"quantile\": [0.1, 0.25, 0.5, 0.75, 0.9],   # Quantiles to predict\n",
    "    \"alpha\": [0.1, 0.5, 1.0, 5.0],             # Regularization strength\n",
    "    \"fit_intercept\": [True, False],            # Whether to fit the intercept\n",
    "    \"solver\": [\"highs\", \"highs-ds\", \"highs-ipm\", \"revised simplex\"],  # Optimization solver\n",
    "    \"solver_options\": [None, {\"maxiter\": 1000}, {\"disp\": True}]       # Solver-specific options\n",
    "}\n",
    "\n",
    "\n",
    "# \"highs\"       : General-purpose solver; fast and supports both dense and sparse inputs. Recommended for most cases.\n",
    "# \"highs-ds\"    : Dual simplex method; robust for sparse data.\n",
    "# \"highs-ipm\"   : Interior point method; efficient for large, dense problems.\n",
    "# \"revised simplex\" : Classical simplex algorithm; slower than \"highs\" but may work better for specific small problems.\n",
    "\n",
    "# solver_options : A dictionary of additional parameters for solver customization.\n",
    "\n",
    "# None            : Uses default solver options.\n",
    "# {\"maxiter\": 1000}  : Sets the maximum number of iterations for the solver to 1000.\n",
    "# {\"disp\": True}     : Enables verbose output to track the solver's progress during optimization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANSACRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition:\n",
    "\"\"\"\n",
    "RANSACRegressor:\n",
    "An iterative algorithm for robustly estimating parameters from a subset of inliers from the complete dataset.\n",
    "RANSAC (Random Sample Consensus) works by repeatedly selecting a random subset of the data, fitting a model, \n",
    "and evaluating the number of inliers, which helps reject outliers.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize RANSACRegressor with default or custom parameters\n",
    "ransac_regressor = RANSACRegressor(\n",
    "    estimator=LinearRegression(),   # Base estimator for model fitting, defaults to LinearRegression\n",
    "    min_samples=0.5,                # Minimum samples chosen randomly for fitting (as fraction of data)\n",
    "    residual_threshold=5.0,         # Maximum residual to be considered as an inlier\n",
    "    max_trials=100,                 # Maximum iterations for random sample selection\n",
    "    max_skips=np.inf,               # Maximum skipped iterations due to invalid samples\n",
    "    stop_n_inliers=np.inf,         # Stop if this many inliers are found\n",
    "    stop_score=np.inf,             # Stop if score exceeds this threshold\n",
    "    stop_probability=0.99,          # Confidence level for stopping the RANSAC iterations\n",
    "    loss='absolute_error',          # Loss function for evaluating the error per sample\n",
    "    random_state=42                 # Random seed for reproducibility\n",
    ")\n",
    "\n",
    "\n",
    "# Hyperparameters:\n",
    "ransac_regressor_hyperparameters = {\n",
    "    \"estimator\": [LinearRegression(), None],   # Base estimator for model fitting\n",
    "    \"min_samples\": [0.1, 0.5, 1],              # Minimum samples required for fitting\n",
    "    \"residual_threshold\": [1.0, 5.0, 10.0],    # Threshold for classifying inliers\n",
    "    \"max_trials\": [50, 100, 500],              # Maximum number of iterations\n",
    "    \"max_skips\": [np.inf, 10, 50],             # Max skipped iterations due to invalid data\n",
    "    \"stop_n_inliers\": [5, 10, np.inf],         # Stop when this many inliers are found\n",
    "    \"stop_score\": [0.5, 1.0, np.inf],          # Stop if score exceeds this value\n",
    "    \"stop_probability\": [0.95, 0.99, 0.999],   # Confidence for stopping iteration\n",
    "    \"loss\": [\"absolute_error\", \"squared_error\"], # Loss function for error calculation\n",
    "    \"random_state\": [None, 42, 0]              # Random seed for reproducibility\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TheilSenRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Theil-Sen Estimator:\n",
    "A robust multivariate regression model that calculates least squares solutions from subsets of samples.\n",
    "It can handle outliers and provides robust parameter estimation using the spatial median.\n",
    "The algorithm computes least squares on a set of subsets of size 'n_subsamples' from the input data.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "\n",
    "theil_sen_regressor_model = TheilSenRegressor(\n",
    "    fit_intercept=True,           # Whether to calculate the intercept\n",
    "    copy_X=True,                  # Whether to copy input data X\n",
    "    max_subpopulation=10000,      # Limit the size of subsets if n choose k is too large\n",
    "    n_subsamples=None,            # Number of subsamples to compute parameters\n",
    "    max_iter=300,                 # Maximum iterations for calculating spatial median\n",
    "    tol=1e-3,                     # Tolerance when calculating the spatial median\n",
    "    random_state=42,              # Random seed for reproducibility\n",
    "    n_jobs=None,                  # Number of parallel jobs for computation\n",
    "    verbose=False                 # Whether to print detailed output\n",
    ")\n",
    "\n",
    "theil_sen_regressor_hyperparameters = {\n",
    "    \"fit_intercept\": [True, False],                 # Whether to calculate intercept\n",
    "    \"copy_X\": [True, False],                        # Whether to copy input X\n",
    "    \"max_subpopulation\": [10000, 5000, 20000],     # Max size of subsets considered\n",
    "    \"n_subsamples\": [None, 10, 20],                # Number of subsamples to compute parameters\n",
    "    \"max_iter\": [100, 300, 500],                   # Maximum iterations for median calculation\n",
    "    \"tol\": [1e-4, 1e-3, 1e-2],                     # Tolerance for spatial median calculation\n",
    "    \"random_state\": [None, 42, 0],                  # Random seed for reproducibility\n",
    "    \"n_jobs\": [None, 1, -1],                        # Number of parallel jobs\n",
    "    \"verbose\": [False, True]                        # Whether to print detailed output\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtaul_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
